{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monotonic Classifiers\n",
    "\n",
    "Some classifiers should never \"flip-flop\" between classes. For example, consider the following classifier that labels system call traces from programs as being benign or malicious programs. No matter how many benign instructions are added to a malicious program, it should never trick the classifier into thinking it is benign.\n",
    "\n",
    "The classifier below takes sequences of system calls obtained from execution traces from malicious and benign programs. Treating each execution trace as a document, we extract a tf-idf[1] vector for feature extraction. Code below is provided that:\n",
    "1. Grabs ground truth traces\n",
    "1. Vectorizes them with tf-idf\n",
    "1. Performs 10-fold cross validation\n",
    "1. Trains a Logistic Regression model\n",
    "\n",
    "Your task as a malware author yourself, is to find direct and indirect ways to break this model so antivirus software cannot detect your code. Approach these tasks in three chunks:\n",
    "1. Manually manipulate a malicious feature vector such that the classifier mistakenly labels it malicious. If you successfully do this once, create a function that given a benign feature vector returns a new one that will be classified as benign.\n",
    "1. Identify features that, given your knowledge of what monotonic classifiers try to solve, could be used to \"flip\" a malicious program into benign one.\n",
    "1. Using the aforementioned features, write a function that transforms a malicious syscall trace (appending is fine) to be classified as benign.\n",
    "1. Modify the classifier so these features can no longer be used to \"flip\" a malicious trace. There's a quick'n'dirty way to do this, but more sophisticated[2] and robust[3] techniques exist if monotonicity is an important feature that your classifier needs.\n",
    "\n",
    "## References\n",
    "* [1] https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "* [2] https://arxiv.org/pdf/1804.03643.pdf\n",
    "* [3] https://www.slideshare.net/MSbluehat/bluehat-v17-detecting-compromise-on-windows-endpoints-with-osquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import random\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## utils\n",
    "def rwalk(directory, pattern):\n",
    "    \"\"\"Recursively search \"directory\" for files that match the Unix shell-style\n",
    "    wildcard given by \"pattern\" (like '*.mp3'). Returns matches as a generator.\"\"\"\n",
    "    for root, dirnames, filenames in os.walk(directory):\n",
    "        for filename in fnmatch.filter(filenames, pattern):\n",
    "            yield os.path.join(root, filename)\n",
    "\n",
    "def gettraces(benignpath='../data/01-monotonic-classifiers/benign-traces',\n",
    "              malpath='../data/01-monotonic-classifiers/malicious-traces'):\n",
    "    return list(rwalk(malpath, '*.trace')), list(rwalk(benignpath, '*.trace'))\n",
    "\n",
    "def get_random_malicious_trace(malpath='../data/01-monotonic-classifiers/malicious-traces'):\n",
    "    \"\"\"Grab the text of a random malicious system call trace.\"\"\"\n",
    "    mal, _ = gettraces(malpath=malpath)\n",
    "    with open(random.choice(mal)) as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the TfidfVectorizer to vectorize ground truth\n",
    "\n",
    "The following extracts vectors from each benign and malicious execution trace and returns four values:\n",
    "1. `X`: the feature vectors\n",
    "1. `y`: the class labels\n",
    "1. `terms`: the list of labels (0 is benign, 1 is malicious)\n",
    "1. `vectorizer`: a TfidfVectorizer which is fit to the terms in the ground truth and can be used to fit new syscall traces with `vectorizer.transform([trace1, trace2, ..., traceN])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(featuredir='../data/01-monotonic-classifiers/feature-vectors'):\n",
    "    pos_traces, neg_traces = gettraces()\n",
    "    pos_y = [1 for _ in pos_traces]\n",
    "    neg_y = [0 for _ in neg_traces]\n",
    "    docs = [open(x).read() for x in pos_traces + neg_traces]\n",
    "    y = np.array(pos_y + neg_y)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(docs)\n",
    "    terms = np.asarray(vectorizer.get_feature_names())\n",
    "    return X, y, terms, vectorizer\n",
    "\n",
    "X, y, terms, vectorizer = vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x16 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 32000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ntcreateprocessex', 'ntcreatethreadex', 'ntcreateuserprocess',\n",
       "       'ntdisplaystring', 'ntdrawtext', 'ntmodifybootentry', 'ntopenfile',\n",
       "       'ntopenkeyex', 'ntopentimer', 'ntquerydirectoryfile', 'ntreadfile',\n",
       "       'ntsavekeyex', 'ntsettimerex', 'ntwritefile', 'regcreatekeyex',\n",
       "       'regsavekeyex'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _heatmap(crosstab):\n",
    "    plt.clf()\n",
    "    p = seaborn.heatmap(crosstab, square=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _cv(X, y, k, name, clf, csvname, modeldir=None, terms=None, resultdir=None):\n",
    "    print('## %s' % name)\n",
    "    print('### Cross Validation')\n",
    "    print('`%s`' % str(cross_val_score(clf, X, y, cv=k)))\n",
    "    print('### CV Confusion Matrix')\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=k)\n",
    "    print('```')\n",
    "    print(pd.crosstab(y, y_pred, rownames=['True'], colnames=['Predicted']))\n",
    "    print('```')\n",
    "    _heatmap(pd.crosstab(y, y_pred, rownames=['True'], colnames=['Predicted'],\n",
    "                         normalize='index'))\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## name\n",
      "### Cross Validation\n",
      "`[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]`\n",
      "### CV Confusion Matrix\n",
      "```\n",
      "Predicted     0     1\n",
      "True                 \n",
      "0          1000     0\n",
      "1             0  1000\n",
      "```\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = _cv(X, y, 10, 'name', LogisticRegression(solver='lbfgs'), 'foo.csv', modeldir='../work', terms=terms, resultdir='../work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.24482262,  2.24424061, -2.14186277, -2.13967196, -2.1405273 ,\n",
       "        2.24523331, -2.13965475, -2.13854639, -2.13845327, -2.1407568 ,\n",
       "       -2.14462209,  2.24613296,  2.24276795,  0.10771154,  2.24801507,\n",
       "        2.2431061 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ntcreateprocessex', 'ntcreatethreadex', 'ntcreateuserprocess',\n",
       "       'ntdisplaystring', 'ntdrawtext', 'ntmodifybootentry', 'ntopenfile',\n",
       "       'ntopenkeyex', 'ntopentimer', 'ntquerydirectoryfile', 'ntreadfile',\n",
       "       'ntsavekeyex', 'ntsettimerex', 'ntwritefile', 'regcreatekeyex',\n",
       "       'regsavekeyex'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n",
    "\n",
    "Let's spend some time familiarizing ourselves with the input data and the classifier. First, we'll examine the dataset in more detail. Then, we'll go over how to interact with the classifier through the vectorizer and `numpy`.\n",
    "\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num malicious traces: 1000\n",
      "num benign traces: 1000\n",
      "malicious trace path: ../data/01-monotonic-classifiers/malicious-traces/0228.trace\n",
      "benign trace path: ../data/01-monotonic-classifiers/benign-traces/0228.trace\n",
      "\n",
      "# Sample Trace\n",
      "RegCreateKeyEx\n",
      "NtModifyBootEntry\n",
      "NtModifyBootEntry\n",
      "NtCreateProcessEx\n",
      "RegCreateKeyEx\n",
      "NtSaveKeyEx\n",
      "NtCr...\n",
      "len(trace): 311230\n"
     ]
    }
   ],
   "source": [
    "# Load all malicious and benign traces from the ground truth dataset\n",
    "maltraces, bentraces = gettraces()\n",
    "print('num malicious traces: %d' % len(maltraces))\n",
    "print('num benign traces: %d' % len(bentraces))\n",
    "print('malicious trace path: %s' % maltraces[0])\n",
    "print('benign trace path: %s' % bentraces[0])\n",
    "\n",
    "# Let's see what a trace file looks like!\n",
    "with open(maltraces[0]) as f:\n",
    "    maltrace = f.read()\n",
    "\n",
    "print('\\n# Sample Trace')\n",
    "print(maltrace[:100] + '...')\n",
    "print('len(trace): %d' % len(maltrace))\n",
    "# i/o basics\n",
    "# numpy basics\n",
    "# classifier basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 1000 malicious and 1000 benign traces, which are simple text files. The traces files contain one [win32 API call](https://docs.microsoft.com/en-us/windows/win32/api/winreg/nf-winreg-regcreatekeyexa) per line. What is the distribution of system calls in this single malicious trace we've been analyzing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NtWriteFile', 2567),\n",
       " ('NtCreateProcessEx', 2440),\n",
       " ('RegCreateKeyEx', 2422),\n",
       " ('RegSaveKeyEx', 2413),\n",
       " ('NtSetTimerEx', 2405),\n",
       " ('NtSaveKeyEx', 2392),\n",
       " ('NtCreateThreadEx', 2350),\n",
       " ('NtModifyBootEntry', 2340),\n",
       " ('NtCreateUserProcess', 250),\n",
       " ('NtQueryDirectoryFile', 242),\n",
       " ('NtDisplayString', 242),\n",
       " ('NtDrawText', 235),\n",
       " ('NtOpenTimer', 233),\n",
       " ('NtReadFile', 231),\n",
       " ('NtOpenKeyEx', 228),\n",
       " ('NtOpenFile', 196)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def frequency(trace):\n",
    "    return Counter(trace.splitlines())\n",
    "frequency(maltrace).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for a single benign trace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NtWriteFile', 628),\n",
       " ('NtOpenFile', 621),\n",
       " ('NtCreateUserProcess', 593),\n",
       " ('NtDrawText', 586),\n",
       " ('NtOpenKeyEx', 577),\n",
       " ('NtOpenTimer', 564),\n",
       " ('NtDisplayString', 557),\n",
       " ('NtReadFile', 550),\n",
       " ('NtQueryDirectoryFile', 545),\n",
       " ('NtCreateThreadEx', 88),\n",
       " ('NtSetTimerEx', 86),\n",
       " ('RegCreateKeyEx', 77),\n",
       " ('RegSaveKeyEx', 73),\n",
       " ('NtSaveKeyEx', 63),\n",
       " ('NtModifyBootEntry', 61),\n",
       " ('NtCreateProcessEx', 54)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(bentraces[0]) as f:\n",
    "    bentrace = f.read()\n",
    "\n",
    "frequency(bentrace).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some of the differences between these two traces? Post your answers in Group Chat!\n",
    "\n",
    "The `Counter` class let's us add two of them together to merge the counts. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NtWriteFile', 3195),\n",
       " ('RegCreateKeyEx', 2499),\n",
       " ('NtCreateProcessEx', 2494),\n",
       " ('NtSetTimerEx', 2491),\n",
       " ('RegSaveKeyEx', 2486),\n",
       " ('NtSaveKeyEx', 2455),\n",
       " ('NtCreateThreadEx', 2438),\n",
       " ('NtModifyBootEntry', 2401),\n",
       " ('NtCreateUserProcess', 843),\n",
       " ('NtDrawText', 821),\n",
       " ('NtOpenFile', 817),\n",
       " ('NtOpenKeyEx', 805),\n",
       " ('NtDisplayString', 799),\n",
       " ('NtOpenTimer', 797),\n",
       " ('NtQueryDirectoryFile', 787),\n",
       " ('NtReadFile', 781)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(frequency(maltrace) + frequency(bentrace)).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer, Numpy, and Classifier\n",
    "\n",
    "This particular classifier relies on a `vectorizer` that turns raw text---like our traces---into a numerical feature vector. This allows us to use our typical machine learning algorithms on text data. Let's create a matrix containing two feature vectors containing the malicious and benign traces from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.35527455,  0.34217016,  0.03640108,  0.03523625,  0.03421702,\n",
       "          0.34071412,  0.02853845,  0.03319779,  0.03392581,  0.03523625,\n",
       "          0.0336346 ,  0.34828554,  0.3501784 ,  0.3737663 ,  0.35265367,\n",
       "          0.35134323],\n",
       "        [ 0.03080502,  0.05020077,  0.33828472,  0.31774805,  0.33429148,\n",
       "          0.03479826,  0.3542577 ,  0.32915731,  0.32174129,  0.31090249,\n",
       "          0.3137548 ,  0.03593919,  0.04905984,  0.35825094,  0.04392567,\n",
       "          0.04164382]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = vectorizer.transform([maltrace, bentrace])\n",
    "print(A.shape)\n",
    "\n",
    "A.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that `vectorizer.transform` takes a list of traces (the raw text from the file, _not_ the path) as input and returns a matrix of values where each row corresponds to the trace and the columns represent the vectorized text, i.e., our features. This means our dataset contains 16 features.\n",
    "\n",
    "Since we now have a matrix of values, we can do simple matrix arithmetic to manipulate the feature vectors. For those not familiar with the library `numpy` (here `import numpy as np`), we can construct `n`-dimensional arrays with `np.array`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    "a = np.array(range(16))\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a 1-dimensional array (a vector) of the values 0--15. We can now do vectorized arithmetic to affect all the values in a matrix without having to waste time looping through each row. For example, the snippet below adds 1 to every other column in the feature vector matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.35527455,  0.34217016,  1.03640108,  0.03523625,  1.03421702,\n",
       "          0.34071412,  1.02853845,  0.03319779,  1.03392581,  0.03523625,\n",
       "          1.0336346 ,  0.34828554,  1.3501784 ,  0.3737663 ,  1.35265367,\n",
       "          0.35134323],\n",
       "        [ 1.03080502,  0.05020077,  1.33828472,  0.31774805,  1.33429148,\n",
       "          0.03479826,  1.3542577 ,  0.32915731,  1.32174129,  0.31090249,\n",
       "          1.3137548 ,  0.03593919,  1.04905984,  0.35825094,  1.04392567,\n",
       "          0.04164382]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have a matrix, how do we use the classifier? Our classifier was built above and stored as `clf`. We can use the `clf.predict()` method to predict whether a vectorized trace is from a malicious or benign program. Note that `1` means malicious and `0` means benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means our first row was classified as malicious and our second row was classified as benign. Considering `A` was constructed by running `vectorizer.transform([maltrace, bentrace])`, this makes perfect sense! Since `A` is just a matrix of values, we can also classify the manipulation of these matrices as we had done above. For example, let's add a vector to `A` and see how it impacts the classifier's output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(A + np.array(range(16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this affected the classification result! Both are now considered malicious. Soon, we'll figure out how to do this in the other direction :). But first..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm Up\n",
    "\n",
    "Complete the following exercises to demonstrate familiarity with the dataset:\n",
    "\n",
    "* How many system calls are there in this dataset in total?\n",
    "* What is the most common system call? For malicious traces only? What about benign?\n",
    "* Complete the function `get_feature_vector(path, vectorizer)` that given a path to a trace and the example vectorizer, returns the feature vector as a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# system calls: 16\n"
     ]
    }
   ],
   "source": [
    "mal_counts = Counter()\n",
    "for path in maltraces:\n",
    "    with open(path) as f:\n",
    "        trace = f.read()\n",
    "        mal_counts += frequency(trace)\n",
    "        \n",
    "ben_counts = Counter()\n",
    "for path in bentraces:\n",
    "    with open(path) as f:\n",
    "        trace = f.read()\n",
    "        ben_counts += frequency(trace)\n",
    "\n",
    "all_counts = mal_counts + ben_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# system calls: 16\n",
      "most common (all): ('NtWriteFile', 5849568)\n",
      "most common (mal): ('NtWriteFile', 3141803)\n",
      "most common (ben): ('NtWriteFile', 2707765)\n",
      "least common (all): ('NtOpenTimer', 2687380)\n",
      "least common (mal): ('NtOpenTimer', 281636)\n",
      "least common (ben): ('NtSetTimerEx', 300542)\n"
     ]
    }
   ],
   "source": [
    "print('# system calls: %d' % len(all_counts))\n",
    "print('most common (all):', all_counts.most_common()[0])\n",
    "print('most common (mal):', mal_counts.most_common()[0])\n",
    "print('most common (ben):', ben_counts.most_common()[0])\n",
    "\n",
    "print('least common (all):', all_counts.most_common()[-1])\n",
    "print('least common (mal):', mal_counts.most_common()[-1])\n",
    "print('least common (ben):', ben_counts.most_common()[-1])\n",
    "\n",
    "def get_feature_vector(path, vectorizer):\n",
    "    with open(path) as f:\n",
    "        return vectorizer.transform([f.read()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Attack\n",
    "\n",
    "You (somehow) have direct access to the feature vectors. Don't ask how, celebrate! Let's try to figure out the difference between malicious and benign feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and Examine Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: It probably makes more sense to have a plot that shows the difference in these distributions.\n",
    "mal_fv = get_feature_vector(maltraces[0], vectorizer)\n",
    "ben_fv = get_feature_vector(bentraces[0], vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious\t\t\tbenign\t\t\t\t\tmalicious - benign\n",
      "  (0, 0)\t0.355274549501\t  (0, 0)\t0.0308050170905\t\t  (0, 15)\t0.309699413365\n",
      "  (0, 1)\t0.34217016038\t  (0, 1)\t0.050200768592\t\t  (0, 14)\t0.308727999159\n",
      "  (0, 2)\t0.0364010808915\t  (0, 2)\t0.338284724716\t\t  (0, 13)\t0.0155153590967\n",
      "  (0, 3)\t0.035236246303\t  (0, 3)\t0.317748046656\t\t  (0, 12)\t0.301118556143\n",
      "  (0, 4)\t0.034217016038\t  (0, 4)\t0.33429148176\t\t  (0, 11)\t0.312346355364\n",
      "  (0, 5)\t0.340714117144\t  (0, 5)\t0.0347982600467\t\t  (0, 10)\t-0.280120204956\n",
      "  (0, 6)\t0.0285384474189\t  (0, 6)\t0.354257696541\t\t  (0, 9)\t-0.275666241\n",
      "  (0, 7)\t0.0331977857731\t  (0, 7)\t0.329157312245\t\t  (0, 8)\t-0.287815482221\n",
      "  (0, 8)\t0.0339258073909\t  (0, 8)\t0.321741289612\t\t  (0, 7)\t-0.295959526472\n",
      "  (0, 9)\t0.035236246303\t  (0, 9)\t0.310902487303\t\t  (0, 6)\t-0.325719249122\n",
      "  (0, 10)\t0.0336345987437\t  (0, 10)\t0.3137548037\t\t  (0, 5)\t0.305915857098\n",
      "  (0, 11)\t0.34828554197\t  (0, 11)\t0.0359391866056\t\t  (0, 4)\t-0.300074465722\n",
      "  (0, 12)\t0.350178398176\t  (0, 12)\t0.0490598420331\t\t  (0, 3)\t-0.282511800353\n",
      "  (0, 13)\t0.373766298594\t  (0, 13)\t0.358250939497\t\t  (0, 2)\t-0.301883643825\n",
      "  (0, 14)\t0.352653671677\t  (0, 14)\t0.043925672518\t\t  (0, 1)\t0.291969391788\n",
      "  (0, 15)\t0.351343232765\t  (0, 15)\t0.0416438194002\t\t  (0, 0)\t0.324469532411\n"
     ]
    }
   ],
   "source": [
    "print('malicious\\t\\t\\tbenign\\t\\t\\t\\t\\tmalicious - benign')\n",
    "diff_fv = mal_fv - ben_fv\n",
    "for mal, ben, diff in reversed(list(zip(str(mal_fv).split('\\n'), \n",
    "                                  str(ben_fv).split('\\n'),\n",
    "                                  str(diff_fv).split('\\n')))):\n",
    "    print('%s\\t%s\\t\\t%s' % (mal, ben, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.35527455,  0.34217016,  0.03640108,  0.03523625,  0.03421702,\n",
       "          0.34071412,  0.02853845,  0.03319779,  0.03392581,  0.03523625,\n",
       "          0.0336346 ,  0.34828554,  0.3501784 ,  0.3737663 ,  0.35265367,\n",
       "          0.35134323]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mal_fv.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! Note the indices where the malicious field is smaller than benign. Let's increase these indices in a malicious vector and see if that causes the class labels to flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Malicious field smaller than benign\n",
      "  (0, 2)\tTrue\n",
      "  (0, 3)\tTrue\n",
      "  (0, 4)\tTrue\n",
      "  (0, 6)\tTrue\n",
      "  (0, 7)\tTrue\n",
      "  (0, 8)\tTrue\n",
      "  (0, 9)\tTrue\n",
      "  (0, 10)\tTrue\n"
     ]
    }
   ],
   "source": [
    "print('\\nMalicious field smaller than benign')\n",
    "print(mal_fv < ben_fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "def feature_vector_malicious_to_benign(fv):\n",
    "    \"\"\"This adds 1 to all indices in a malicious vector that are smaller than the benign vector to \n",
    "    transform it into a vector that will classify as benign.\"\"\"\n",
    "    delta = np.array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
    "    return fv + delta\n",
    "print(clf.predict(mal_fv))\n",
    "print(clf.predict(feature_vector_malicious_to_benign(mal_fv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have successfully switched the label from malicious (1) to benign (0). Let's see if our function works on all the malicious samples now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: Counter({1: 1000})\n",
      "mutated:  Counter({0: 1000})\n"
     ]
    }
   ],
   "source": [
    "def mutate_all_malicious(mutate_fn):\n",
    "    maltraces, _ = gettraces()\n",
    "    A = vectorizer.transform([open(x).read() for x in maltraces])\n",
    "    A_mutated = mutate_fn(A)\n",
    "    \n",
    "    print('original:', Counter(clf.predict(A)))\n",
    "    print('mutated: ', Counter(clf.predict(A_mutated)))\n",
    "    \n",
    "mutate_all_malicious(feature_vector_malicious_to_benign) # lambda x: x for notebooks version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huzzah! Our malware is now undetectable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indirect Attack Part 1 (Find terms)\n",
    "\n",
    "So we've made our malware undetectable (above), but we did so by directly manipulating the feature vector. This assumes a powerful and/or dedicated attacker and we're a bit lazy. How can we alter our malware's _behavior_ such that our malware is classified as benign software? Let's identify `terms` that are more likely to be associated with benign software than malicious software by finding _negative_ coefficients in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-2.144622087973715, 'ntreadfile'),\n",
       " (-2.1418627669686718, 'ntcreateuserprocess'),\n",
       " (-2.1407567984612896, 'ntquerydirectoryfile'),\n",
       " (-2.1405272962289321, 'ntdrawtext'),\n",
       " (-2.1396719582510686, 'ntdisplaystring'),\n",
       " (-2.1396547495478848, 'ntopenfile'),\n",
       " (-2.1385463916610412, 'ntopenkeyex'),\n",
       " (-2.1384532744136893, 'ntopentimer'),\n",
       " (0.10771154443371385, 'ntwritefile'),\n",
       " (2.2427679460606096, 'ntsettimerex'),\n",
       " (2.2431060978323236, 'regsavekeyex'),\n",
       " (2.2442406107176387, 'ntcreatethreadex'),\n",
       " (2.244822624665082, 'ntcreateprocessex'),\n",
       " (2.245233313408201, 'ntmodifybootentry'),\n",
       " (2.2461329578438209, 'ntsavekeyex'),\n",
       " (2.2480150712142537, 'regcreatekeyex')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(clf.coef_[0], terms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A-ha! These negatively weighted features will do nicely. This means we can simply append a lot of `ntreadfile` calls to our malware and it'll push the classification towards benign. Let's try it for one, random malicious trace. Consider that we can read as many files as we want in code and _not_ disrupt the malicious behavior that occurred earlier. Don't be shy about adding a lot of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = get_random_malicious_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = vectorizer.transform([foo])\n",
    "v2 = vectorizer.transform([foo + '\\n' + '\\n'.join(itertools.repeat('ntreadfile', 100000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! Looks like we can force the classification to flip by only indirectly manipulating the feature vector. Do you think this case is more or less reasonable than directly manipulating feature vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indirect Attack Part 2 (Adversarial Sample Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adversarial_sample(path):\n",
    "    with open(path) as f:\n",
    "        s = f.read()\n",
    "        numsyscalls = len(s.split())\n",
    "        s_benign = s + '\\n' + '\\n'.join(itertools.repeat('ntreadfile', numsyscalls))\n",
    "        return s, s_benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186656\n",
      "326543\n"
     ]
    }
   ],
   "source": [
    "s, s_benign = gen_adversarial_sample('../data/01-monotonic-classifiers/malicious-traces/0999.trace')\n",
    "print(len(s))\n",
    "print(len(s_benign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It works!\n",
    "clf.predict(vectorizer.transform([s, s_benign]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1000})\n",
      "Counter({0: 1000})\n"
     ]
    }
   ],
   "source": [
    "orig = []\n",
    "mutated = []\n",
    "for maltrace in maltraces:\n",
    "    mal, adv = gen_adversarial_sample(maltrace)\n",
    "    malvec = vectorizer.transform([mal])\n",
    "    advvec = vectorizer.transform([adv])\n",
    "    orig.append(clf.predict(malvec))\n",
    "    mutated.append(clf.predict(advvec))\n",
    "print(Counter([x[0] for x in orig]))\n",
    "print(Counter([x[0] for x in mutated]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only does it work on a single example, but it breaks everything we saw in the ground truth!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Classifier Monotonic\n",
    "\n",
    "A simple way to make a classifier monotonic for our purposes is to not allow attackers to abuse negative coefficient features. Add a vector to `clf.coef` such that there are no longer negative coefficients, and demonstrates this defeats your adversarial generation function from the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can accomplish this by:\n",
    "* Identify the index in `clf.coef_` for the feature you abused\n",
    "* Set its weight to `0.0`\n",
    "* Rerunning our classification examples from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_[0][clf.coef_.argmin()] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original malicious traces\n",
      "Counter({1: 1000})\n",
      "Adversarial malicious traces\n",
      "Counter({1: 1000})\n",
      "Original benign traces\n",
      "Counter({0: 1000})\n"
     ]
    }
   ],
   "source": [
    "maltraces, bentraces = gettraces()\n",
    "orig = []\n",
    "mutated = []\n",
    "benign = []\n",
    "for maltrace in maltraces:\n",
    "    mal, adv = gen_adversarial_sample(maltrace)\n",
    "    malvec = vectorizer.transform([mal])\n",
    "    advvec = vectorizer.transform([adv])\n",
    "    orig.append(clf.predict(malvec))\n",
    "    mutated.append(clf.predict(advvec))\n",
    "print('Original malicious traces')\n",
    "print(Counter([x[0] for x in orig]))\n",
    "print('Adversarial malicious traces')\n",
    "print(Counter([x[0] for x in mutated]))\n",
    "\n",
    "# What about the benign examples?\n",
    "for bentrace in bentraces:\n",
    "    benvec = get_feature_vector(bentrace, vectorizer)\n",
    "    benign.append(clf.predict(benvec))\n",
    "print('Original benign traces')\n",
    "print(Counter([x[0] for x in benign]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it works, but we more or less nullified the utility of the feature aside from its interactions with other variables when constructing the model. Sometimes keeping this is desirable, but it could suggest that this feature provides more drawbacks than benefits. This further demonstrates the importance of feature engineering: if the features are useful, but when known can be weaponized by attackers, perhaps it is better to sacrifice accuracy in order to have more resilient models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
